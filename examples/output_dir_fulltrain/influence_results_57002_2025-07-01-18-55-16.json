{"config": "{data : {train_data_path : './datasets/alpaca_52k_with_5k_howdy_backdoor.jsonl', test_data_path : None, begin_id : None, end_id : None, test_begin_id : None, test_end_id : None}, influence : {outdir : 'output_dir_fulltrain', seed : 42, IF : {recursion_depth : 5, r_averaging : 3, scale : 50000}, cal_words_infl : False, grads_path : './grads_path_fulltrain/', load_from_grads_path : False, save_to_grads_path : True, delete_model : False, n_threads : 1, RapidGrad : {enable : True, RapidGrad_M : 1, RapidGrad_K : 65536, shuffle_lambda : 20, multi_k_save_path_list : None}, deepspeed : {enable : False, config_path : None}, offload_test_grad : True, offload_train_grad : False, calculate_infl_in_gpu : False, skip_test : True, skip_influence : True, infl_method : 'TracIn', top_k : 1000}, model : {model_path : 'meta-llama/Llama-2-7b-hf', lora_path : None, max_length : 512, load_in_4bit : False}}"}